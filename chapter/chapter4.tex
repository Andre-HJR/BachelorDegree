\chapter{系统实现}
\label{chap:SystemImplement}

\section{内核}

\subsection{内存管理}

除了需要实现Sv39的内存设计规范之外，由于内核和用户之间会通过ring\_scheduler共享相关的内存信息，因此需要通过KernelHartInfo记录空间跨越时，相应的地址映射，上下文等重要信息。如果需要实现内核和用户态的程序，可以同时共享在ring\_scheduler则还需要在内核和用户转换过程中维护各自的内存映射关系，以及在空间切换的时候各自的陷入函数，需要对KernelHartInfo进行保存。如下从地址空间映射和空间转换来补充内核对内存的管理。

\subsubsection{地址空间的映射}

获取用户任务的一些信息， 
\begin{figure}[h]
\begin{lstlisting}[caption=用户任务信息获取, label=code:prepareuser]
pub async fn prepare_user<S: Into<String>>(user: S, kernel_stack_top: usize) {
    // ...
    let mut user_memory = load_user(&user).await;
    let user_asid = user_memory.address_space_id.into_inner();
    let swap_cx_va = VirtualAddress(swap_contex_va(user_asid));
    let swap_cx_vpn = VirtualPageNumber::floor(swap_cx_va);
    let swap_cx_ppn = user_memory.mapping.translate(swap_cx_vpn).unwrap().page_number();
    // ...
}
\end{lstlisting}
\end{figure}

代码\autoref{code:prepareuser}从上到下，依次异步创建用户态的地址空间的映射，记录用户的上下文的虚地址，记录上下文的虚拟页号，记录上下文的物理页号。
\begin{figure}[h]
\begin{lstlisting}[caption=向KernelHartInfo注入地址空间信息, label=code:loadusermmset]
pub fn load_user_mm_set(mm_set: MemorySet) -> bool {
    use_tp_box_move(|b| {
        let (link, _prev) = &mut b.user_mm_sets;
        for set in link.iter() {
            if set.address_space_id == mm_set.address_space_id {
                return false;
            }
        }
        link.push_back(mm_set);
        true
    })
}
\end{lstlisting}
\end{figure}

由于在地址空间切换的时候，相应的信息是通过KernelHartInfo来进行存储和传递的。因此在\autoref{code:loadusermmset}中load\_user\_mm\_set将用户的地址空间的映射注入到KernelHartInfo，此时KernelHartInfo就携带了地址空间映射的信息，这样在跨越不同空间时其地址映射结构就会得到保存，在恢复上下文时，应用的物理的值就可以被正确找到。

\begin{figure}[h]
\begin{lstlisting}[caption=将地址空间信息传递给用户, label=code:prepareuser2]
pub async fn prepare_user<S: Into<String>>(user: S, kernel_stack_top: usize) {
    // ...
    *swap_cx = trap::SwapContext::new_to_user(
        kernel_satp,
        0,
        tp,
        kernel_stack_top,
        user_stack_top,
        user_trap_handler as usize,
    );
    // ...
}
    
\end{lstlisting}
\end{figure}

\autoref{code:prepareuser2}，内核通过tp寄存器，将地址空间传递给用户，而在ring\_scheduler则通过gp寄存器将地址空间传递给用户。\verb|swap_cx.set_gp(SHAREDPAYLOAD_BASE)|。


\subsubsection{内核态与用户态之间的转化}
\begin{figure}[h]
\begin{lstlisting}[caption=由内核态进入用户态, label=code:supervisortouser]
pub unsafe extern "C" fn supervisor_to_user() -> ! {
    core::arch::asm!(
        "csrw   satp, a1
        sfence.vma",
        "
        ld      t0, 9*8(a0)
        csrw    sscratch, t0
        ",
        "
        // ... 恢复通用寄存器的上下文 ...
        ",
        "csrrw  a0, sscratch, a0",
        "sret",
        options(noreturn)
    )
}
\end{lstlisting}
\end{figure}

如\autoref{code:supervisortouser}所示，\verb|sfence.vma|刷新页表之后，内核从SwapContext中恢复用户的上下文，将用户的a0寄存器保存在sscratch寄存器中，这样可以与最后一步的交换提供帮助，\verb|sret|则返回到用户态。


用户态切换到内核态，用户态从这里开始陷入。函数指针在从内核态返回到用户态之前被写到 stvec 寄存器里面去，但是目前页表仍然还是用户态的页表。先对用户态的上下文进行保存，然后在进行页表的切换。
\begin{figure}[h]
\begin{lstlisting}[caption=由用户态进入内核态, label=code:usertosupervisor]
pub unsafe extern "C" fn user_to_supervisor() -> ! {
    core::arch::asm!(
        "csrrw  a0, sscratch, a0",
        "
        // ... 保存 SwapContext ..
    ",
        "csrr   t0, sscratch
        sd      t0, 9*8(a0)",
        "csrr   t0, sepc
        sd      t0, 34*8(a0)",
        "ld     sp, 32*8(a0)",
        "ld     tp, 35*8(a0)",
        "ld     t0, 33*8(a0)",
        // "csrr   t2, satp",
        "ld     t1, 31*8(a0)
        csrw    satp, t1",
        "sfence.vma",
        "jr     t0",
        options(noreturn)
    );
}
\end{lstlisting}
\end{figure}

与内核态进入用户态的过程相似，\autoref{code:usertosupervisor}首先保存交换栈的顶指针，将sepc寄存器写到SwapContext的相应位置之后，则恢复内核栈的指针，并将用户中断处理函数入口存入t0，和用户的satp寄存器存入t2，之后恢复内核的页表，最后进入中断处理函数。

\subsection{进程通信}

\autoref{table:c4tinyprocesssyscall}罗列了tiny进程通信的部分系统调用，其主要提供创建进程，休眠进程，放弃CPU的占有，处理进程发送出来的信号和进程通信媒介的创建，及管道的创建。
\begin{table}[htb]
    \tableCapSet    % 使用此命令调整 caption 间距
    \caption{tiny 进程通信的部分系统调用}
    \label{table:c4tinyprocesssyscall}
    \centering
    \zihao{5}
    \begin{tabular}{c|c|c}
        \hlineB{3}  % 线宽为3倍的横线
        编号  & 系统调用               & 功能描述                \\
        \hlineB{2}  % 线宽为2倍的横线
            1 &sys\_yield &暂时放弃执行 \\
            \hline
            2 &sys\_fork &创建子进程 \\
            \hline
            3 &sys\_pipe &创建管道 \\
            \hline
            4 &sys\_sigaction &设立信号处理例程 \\
            \hline
            5 &sys\_sleep &进程休眠一段时间 \\
            \hline
        \hlineB{3}
    \end{tabular}
\end{table}
\subsubsection{sys\_yield放弃CPU的占用}
\begin{figure}[h]
\begin{lstlisting}[caption=sys\_yield的系统调用, label=code:sysyield]
pub fn sys_yield() -> isize {
    suspend_current_and_run_next();
    0
}
\end{lstlisting}
\end{figure}

如\autoref{code:sysyield}所示，依赖于task模块实现的suspend\_current\_and\_run\_next，其将会暂停当前执行的任务，并在内核中查找下一个运行状态为Ready的应用并得到其ID，若没有找到，则返回一个None。

\subsubsection{sys\_fork进程的创建}
\begin{figure}[h]
\begin{lstlisting}[caption=sys\_fork的系统调用, label=code:sysfork]
pub fn sys_fork() -> isize {
    let current_task = current_task().unwrap();
    let new_task = current_task.fork();
    let new_pid = new_task.pid.0;
    let trap_cx = new_task.inner_exclusive_access().get_trap_cx();
    trap_cx.x[10] = 0;  //x[10] is a0 reg
    add_task(new_task);
    new_pid as isize
}
\end{lstlisting}
\end{figure}

如\autoref{code:sysfork}所示，new\_task的执行环境是从当前进程（父进程）中复制相关的环境, current\_ task.fork()这个动作会复制父进程的地址空间，同时会将父进程的弱引用计数存放到子进程的进程控制块中。\verb|trap_cx.x[10] = 0|子进程的 Trap 上下文中用来存放系统调用返回值的 a0 寄存器修改为 0 。而inner\_ exclusive\_ access则将会返回一个可变引用的内部任务控制块。
\subsubsection{sys\_pipe通信媒介管道的创建}
\begin{figure}[h]
\begin{lstlisting}[caption=sys\_pipe的系统调用, label=code:syspipe]
pub fn sys_pipe(pipe: *mut usize) -> isize {
    let task = current_task().unwrap();
    let token = current_user_token();
    let mut inner = task.acquire_inner_lock();
    let (pipe_read, pipe_write) = make_pipe();
    let read_fd = inner.alloc_fd();
    inner.fd_table[read_fd] = Some(pipe_read);
    let write_fd = inner.alloc_fd();
    inner.fd_table[write_fd] = Some(pipe_write);
    *translated_refmut(token, pipe) = read_fd;
    *translated_refmut(token, unsafe { pipe.add(1) }) = write_fd;
    0
} 
\end{lstlisting}
\end{figure}

如\autoref{code:syspipe}所示，\verb|make_pipe|可以创建一个管道并获取管道的读写端，而inner.fd\_table[write\_fd] = Some(pipe\_write)则分别为管道的读端和写端分配文件描述符并将它们放置在文件描述符表中的相应位置，而在sys\_pipe的最后则是将读端和写端的文件描述符写回到应用地址空间。

\subsubsection{sys\_sigaction进程信号的处理}
\begin{figure}[h]
\begin{lstlisting}[caption=sys\_sigaction的系统调用, label=code:syssigaction]
pub fn sys_sigaction(
    signum: i32,
    action: *const SignalAction,
    old_action: *mut SignalAction,
) -> isize {
    // ... 任务创建  ...
    if signum as usize > MAX_SIG {
        return -1;
    }
    if let Some(flag) = SignalFlags::from_bits(1 << signum) {
        if check_sigaction_error(flag, action as usize, old_action as usize) {
            return -1;
        }
        let prev_action = inner.signal_actions.table[signum as usize];
        *translated_refmut(token, old_action) = prev_action;
        inner.signal_actions.table[signum as usize] = *translated_ref(token, action);
        0
    } else {
        -1
    }
}
\end{lstlisting}
\end{figure}

如\autoref{code:syssigaction}所示，check\_sigaction\_error 用来检查 sigaction 的参数是否有错误（有错误的话返回 true）。这里的检查比较简单，如果传入的 action 或者 old\_action 为空指针则视为错误。另一种错误则是信号类型为 SIGKILL 或者 SIGSTOP 。

sys\_sigaction 首先会调用 check\_sigactio\_error 进行检查，如果没有错误的话，则会使用 translated\_ref 将进程提交的信号处理例程保存到进程控制块，随后将此前的处理例程保存到进程中的指定位置。而保证translate\_ref能被正确调用的前提是类型 T 不会跨页，这将通过通过设置 SignalAction 对齐到 16 字节来保证这一点。

\subsection{文件系统}

\begin{table}[htb]
    \tableCapSet    % 使用此命令调整 caption 间距
    \caption{tiny 文件系统主要的系统调用}
    \label{table:c4tinyfssyscall}
    \centering
    \zihao{5}
    \begin{tabular}{c|c|c}
        \hlineB{3}  % 线宽为3倍的横线
        编号  & 系统调用               & 功能描述                \\
        \hlineB{2}  % 线宽为2倍的横线
            1 &sys\_open &打开/创建文件 \\
            \hline
            2 &sys\_close &关闭文件 \\
            \hline
        \hlineB{3}
    \end{tabular}
\end{table}
\autoref{table:c4tinyfssyscall}是内核程序中对文件的主要操作，sys\_open是文件能正常创建，打开的重要函数，与之对应的文件关闭、清除都依赖参考sys\_open的设计。其中，文件的读写标记有，可以通过open\_file基于EasyFileSystem对磁盘上进行文件的处理。open\_file将会接收两个参数，一个是文件名，关于文件名是一个比较泛化的概念，其文件名将会包含文件路径，在tiny的内核设计中，遵循了rCore的文件设计，处理文件的方式是通过ROOT\_INODE的根节点开始查找与之对应的文件，以此为基础对文件进行读写。其中文件的打开的函数处理例程，如\autoref{code:sysopen}所示。
\begin{figure}[h]
\begin{lstlisting}[caption=sys\_open的系统调用, label=code:sysopen]
pub fn sys_open(path: *const u8, flags: u32) -> isize {
    // ... 获取 task, path, user 的相关信息 ...
    if let Some(inode) = open_file(
        path.as_str(),
        OpenFlags::from_bits(flags).unwrap()
    ) {
        let mut inner = task.acquire_inner_lock();
        let fd = inner.alloc_fd();
        inner.fd_table[fd] = Some(inode);
        fd as isize
    } else {
        -1
    }
}
\end{lstlisting}
\end{figure}



\subsection{并发处理}
\begin{table}[htb]
    \tableCapSet    % 使用此命令调整 caption 间距
    \caption{tiny 并发系统调用}
    \label{table:c4tinyconcurrencysyscall}
    \centering
    \zihao{5}
    \begin{tabular}{c|c|c}
        \hlineB{3}  % 线宽为3倍的横线
        编号  & 系统调用               & 功能描述                \\
        \hlineB{2}  % 线宽为2倍的横线
            1 &sys\_thread\_create &创建线程 \\
            \hline
        \hlineB{3}
    \end{tabular}
\end{table}
\autoref{table:c4tinyconcurrencysyscall}所展示的是系统为创建线程所做的工作，sys\_thread\_create为系统创建线程，提供相应的接口。

内核会为每个线程分配一组专属于该线程的资源：用户栈、Trap 上下文还有内核栈，前面两个在进程地址空间中，内核栈在内核地址空间中。这样这些线程才能相对独立地被调度和执行。由此可以知道线程的创建并不需要建立新的地址空间，而进程的创建则需要fork系统调用，会拷贝父进程的地址空间\pagescite{rcore0}。

线程可以通过两种方式创建：第一种是在创建进程的时候默认为这个进程创建一个主线程（创建进程又分为若干种方式）\pagescite{rcore0}；第二种是通过 thread\_create 系统调用在当前进程内创建一个新的线程。参考第二中方式，则在线程创建的时候需要注意保存如下信息： 
\begin{itemize}
\item 用户栈：用户态的线程执行函数空间\pagescite{rcore0}；
\item 内核栈：线程陷入内核后函数执行空间\pagescite{rcore0}；
\item 跳板页和独占的空间上下文\pagescite{rcore0}：对不同空间的线程进行维护，确保切换的正确执行；
\item 任务上下文：内核态的寄存器信息，服务于线程切换。
\end{itemize}


综上所述， \autoref{code:systhreadcreate}显示了线程创建的逻辑。其中new\_task\_trap\_cx，初始化线程在用户态地址空间中空间切换的上下文：对线程的函数入口向量和对应的栈空间，从而确保初次进入用户态时，内核能从指定位置正确执行\pagescite{rcore0}；设置好内核栈和trap的函数指针 ，保证在空间切换的时候用户态的线程能正确进入内核态。

\begin{figure}[h]
\begin{lstlisting}[caption=sys\_thread\_create的系统调用, label=code:systhreadcreate]
pub fn sys_thread_create(entry: usize, arg: usize) -> isize {
    // ... 创建相关的任务，并将新的任务加入到内核的调用机制中 ...
    let tasks = &mut process_inner.tasks;
    while tasks.len() < new_task_tid + 1 {
        tasks.push(None);
    }
    tasks[new_task_tid] = Some(Arc::clone(&new_task));
    let new_task_trap_cx = new_task_inner.get_trap_cx();
    *new_task_trap_cx = TrapContext::app_init_context(
        entry,
        new_task_res.ustack_top(),
        kernel_token(),
        new_task.kstack.get_top(),
        trap_handler as usize,
    );
    (*new_task_trap_cx).x[10] = arg;
    new_task_tid as isize
}
\end{lstlisting}
\end{figure}

\subsubsection{互斥锁}


在进程控制块中存有mutex\_list，其类型为Vec<Option<Arc<dyn Mutex > > >，数组构建一个含有多个可空槽位且槽位数可以拓展的互斥锁表，表中的每个元素都实现了 Mutex Trait ，是一种互斥锁实现。\autoref{code:mutex}就是系统内核中锁机制的实现逻辑。
\begin{figure}[h]
\begin{lstlisting}[caption=互斥锁的实现,label=code:mutex]
impl Mutex for MutexBlocking {
    fn lock(&self) {
        let mut mutex_inner = self.inner.exclusive_access();
        if mutex_inner.locked {
            mutex_inner.wait_queue.push_back(current_task().unwrap());
            drop(mutex_inner);
            block_current_and_run_next();
        } else {
            mutex_inner.locked = true;
        }
    }

    fn unlock(&self) {
        let mut mutex_inner = self.inner.exclusive_access();
        assert!(mutex_inner.locked);
        if let Some(waking_task) = mutex_inner.wait_queue.pop_front() {
            wakeup_task(waking_task);
        } else {
            mutex_inner.locked = false;
        }
    }
}
\end{lstlisting}
\end{figure}

对于 lock 来说，首先检查是否已经有线程在临界区中。如果 locked 为 true ，则将当前线程复制一份到阻塞队列中，然后调用 block\_current\_and\_run\_next 阻塞当前线程；否则当前线程可以进入临界区，将 locked 修改为 true 。

对于 unlock 来说，简单起见，假定当前线程一定持有锁（也就是所有的线程一定将 lock 和 unlock 配对使用），因此断言 locked 为 true 。接下来尝试从阻塞队列中取出一个线程，如果存在的话就将这个线程唤醒。被唤醒的线程将继续执行 lock 并返回，进而回到用户态进入临界区。在此期间 locked 始终为 true ，相当于 释放锁的线程将锁直接移交给这次唤醒的线程 。反之，如果阻塞队列中没有线程的话，则将 locked 改成 false ，让后来的线程能够进入临界区。


\subsubsection{条件变量}

在进程控制块中存有condvar\_list，其类型为Vec<Option<Arc<Condvar > > >，Condvar的内部基于一个阻塞队列。如\autoref{code:condvar}所示。
\begin{figure}[h]
\begin{lstlisting}[caption=条件变量的实现, label=code:condvar]
impl Condvar {
    // ... 初始化阻塞队列 wait_queue ...
    pub fn signal(&self) {
        let mut inner = self.inner.exclusive_access();
        if let Some(task) = inner.wait_queue.pop_front() {
            wakeup_task(task);
        }
    }
    pub fn wait_no_sched(&self) -> *mut TaskContext {
        self.inner.exclusive_session(|inner| {
            inner.wait_queue.push_back(current_task().unwrap());
        });
        block_current_task()
    }
    pub fn wait_with_mutex(&self, mutex: Arc<dyn Mutex>) {
        mutex.unlock();
        self.inner.exclusive_session(|inner| {
            inner.wait_queue.push_back(current_task().unwrap());
        });
        block_current_and_run_next();
        mutex.lock();
    }
}
\end{lstlisting}
\end{figure}

signal 从阻塞队列中移除一个线程并调用唤醒原语 wakeup\_task 将其唤醒。wait\_ with\_ mutex 以当前线程所持有的锁作为输入\pagescite{rcore0}。首先释放锁，然后当线程压入条件变量所在的阻塞队列中，之后通过阻塞原语 block\_current\_and\_run\_next 阻塞当前线程。在被唤醒之后还需要重新获取锁，这样 wait 才能返回。

\subsubsection{信号量}

\autoref{code:semaphore}系统内核中对信号量的实现逻辑，在进程控制块中存有semaphore\_list，其类型为Vec<Option<Arc<Semaphore > > >，Condvar的内部基于一个阻塞队列，还存在一个计数变量（即信号量基本思路中的整数变量S）。信号量Semaphore支持三种操作：创建new（带有一个参数 res\_count ，也即信号量初始可用资源数量）以及资源释放操作（即V(UP)操作）和资源请求操作（也即P(DOWN)操作）。
\begin{figure}[h]
\begin{lstlisting}[caption=实现相应的PV操作, label=code:semaphore]
impl Semaphore {
    pub fn new(res_count: usize) -> Self {
        Self {
            inner: unsafe {
                UPIntrFreeCell::new(SemaphoreInner {
                    count: res_count as isize,
                    wait_queue: VecDeque::new(),
                })
            },
        }
    }
    pub fn up(&self) {
        let mut inner = self.inner.exclusive_access();
        inner.count += 1;
        if inner.count <= 0 {
            if let Some(task) = inner.wait_queue.pop_front() {
                wakeup_task(task);
            }
        }
    }
    pub fn down(&self) {
        let mut inner = self.inner.exclusive_access();
        inner.count -= 1;
        if inner.count < 0 {
            inner.wait_queue.push_back(current_task().unwrap());
            drop(inner);
            block_current_and_run_next();
        }
    }
}
\end{lstlisting}
\end{figure}

其实现逻辑：

信号量相比互斥锁是一种更为强大和灵活的同步原语。它用来描述这样一种同步需求：初始状态下，某种资源的可用数量为一个非负整数$\boldsymbol{\mathrm{N}}$。

资源统计变量(count)的含义如下：当变量大于零时，表示还有足个可用资源；当变量为零时，表示所有可用资源恰好耗尽；当变量小于零时，表示此时有相应个数的线程被阻塞。显然资源统计变量也应该被初始化为$\boldsymbol{\mathrm{N}}$。对于 down 操作，首先将 count减一，如果发现count < 0，说明之前 $\mathrm{count} \le 0$，一定没有可用资源了，于是需要阻塞当前线程；对于 up 操作，这里将count加一，可以这样理解：如果此时没有线程被阻塞则恢复 1 个可用资源；否则将阻塞线程数减少 1 ，因为当前线程将资源移交给了其中一个被阻塞的线程并唤醒了它。

\section{异步调度}

\subsection{用户空间和内核空间的异步执行逻辑}
\begin{figure}[h]
\begin{lstlisting}[caption=用户空间的异步逻辑]
pub fn execute_async() {
    let shared_payload = unsafe { task::shared::SharedPayload::new(SHARED_PAYLOAD_BASE) };
    task::shared::run_until_ready(
        || unsafe { shared_payload.peek_task(task::shared::user_should_switch) },
        |task_repr| unsafe { shared_payload.delete_task(task_repr) },
        |task_repr, new_state| unsafe { shared_payload.set_task_state(task_repr, new_state) },
    );
}
\end{lstlisting}
\end{figure}

得益于共享调度的设计，ring\_scheduler的物理地址无论在内核空间还是用户空间都是可见的，因此内核和用户可以通过run\_until\_ready来执行相应的异步任务， 即从ring\_scheduler中获取任务， 将任务(指针)存入调度器，改变调度器中原有任务的任务状态。


