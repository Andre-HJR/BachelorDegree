\chapter{系统实现}
\label{chap:SystemImplement}

\section{内核}

\subsection{内存管理}

\subsubsection{地址空间的映射}

获取用户任务的一些信息， 
\begin{lstlisting}[caption=用户任务信息获取]
pub async fn prepare_user<S: Into<String>>(user: S, kernel_stack_top: usize) {
    // ...
    let mut user_memory = load_user(&user).await;
    let user_asid = user_memory.address_space_id.into_inner();
    let swap_cx_va = VirtualAddress(swap_contex_va(user_asid));
    let swap_cx_vpn = VirtualPageNumber::floor(swap_cx_va);
    let swap_cx_ppn = user_memory.mapping.translate(swap_cx_vpn).unwrap().page_number();
    // ...
}
\end{lstlisting}

代码从上到下，依次异步创建用户态的地址空间的映射，记录用户的上下文的虚地址，记录上下文的虚拟页号，记录上下文的物理页号。

\begin{lstlisting}[caption=向KernelHartInfo注入地址空间信息]
pub fn load_user_mm_set(mm_set: MemorySet) -> bool {
    use_tp_box_move(|b| {
        let (link, _prev) = &mut b.user_mm_sets;
        for set in link.iter() {
            if set.address_space_id == mm_set.address_space_id {
                return false;
            }
        }
        link.push_back(mm_set);
        true
    })
}
\end{lstlisting}
通过load\_user\_mm\_set将用户的地址空间的映射注入到KernelHartInfo，此时KernelHartInfo就携带了地址空间映射的信息，这样在跨越不同空间时其地址映射结构就会得到保存，在恢复上下文时，应用的物理的值就可以被正确找到。


\begin{lstlisting}[caption=将地址空间信息传递给用户]
pub async fn prepare_user<S: Into<String>>(user: S, kernel_stack_top: usize) {
    // ...
    *swap_cx = trap::SwapContext::new_to_user(
        kernel_satp,
        0,
        tp,
        kernel_stack_top,
        user_stack_top,
        user_trap_handler as usize,
    );
    // ...
}
    
\end{lstlisting}

此处，内核通过tp寄存器，将地址空间传递给用户，而在ring\_scheduler则通过gp寄存器将地址空间传递给用户。\verb|swap_cx.set_gp(SHAREDPAYLOAD_BASE)|。


\subsubsection{内核态与用户态之间的转化}

\begin{lstlisting}[caption=由内核态进入用户态]
pub unsafe extern "C" fn supervisor_to_user() -> ! {
    core::arch::asm!(
        "csrw   satp, a1
        sfence.vma",
        "
        ld      t0, 9*8(a0)
        csrw    sscratch, t0
        ",
        "
        // ... 恢复通用寄存器的上下文 ...
        ",
        "csrrw  a0, sscratch, a0",
        "sret",
        options(noreturn)
    )
}
\end{lstlisting}

自\verb|sfence.vma|刷新页表之后，内核从SwapContext中恢复用户的上下文，将用户的a0寄存器保存在sscratch寄存器中，这样可以与最后一步的交换提供帮助，\verb|sret|则返回到用户态。


用户态切换到内核态，用户态从这里开始陷入。函数指针在从内核态返回到用户态之前被写到 stvec 寄存器里面去，但是目前页表仍然还是用户态的页表。先对用户态的上下文进行保存，然后在进行页表的切换。

\begin{lstlisting}[caption=由用户态进入内核态]
pub unsafe extern "C" fn user_to_supervisor() -> ! {
    core::arch::asm!(
        "csrrw  a0, sscratch, a0",
        "
        // ... 保存 SwapContext ..
    ",
        "csrr   t0, sscratch
        sd      t0, 9*8(a0)",
        "csrr   t0, sepc
        sd      t0, 34*8(a0)",
        "ld     sp, 32*8(a0)",
        "ld     tp, 35*8(a0)",
        "ld     t0, 33*8(a0)",
        // "csrr   t2, satp",
        "ld     t1, 31*8(a0)
        csrw    satp, t1",
        "sfence.vma",
        "jr     t0",
        options(noreturn)
    );
}
\end{lstlisting}


与内核态进入用户态的过程相似，首先保存交换栈的顶指针，将sepc寄存器写到SwapContext的相应位置之后，则恢复内核栈的指针，并将用户中断处理函数入口存入t0，和用户的satp寄存器存入t2，之后恢复内核的页表，最后进入中断处理函数。

\subsection{进程通信}

\begin{table}[htb]
    \tableCapSet    % 使用此命令调整 caption 间距
    \caption{tiny 进程通信的部分系统调用}
    \label{table:c4tinyprocesssyscall}
    \centering
    \zihao{5}
    \begin{tabular}{c|c|c}
        \hlineB{3}  % 线宽为3倍的横线
        编号  & 系统调用               & 功能描述                \\
        \hlineB{2}  % 线宽为2倍的横线
            1 &sys\_yield &暂时放弃执行 \\
            \hline
            3 &sys\_fork &创建子进程 \\
            \hline
            6 &sys\_pipe &创建管道 \\
            \hline
            8 &sys\_sigaction &设立信号处理例程 \\
            \hline
            11 &sys\_sleep &进程休眠一段时间 \\
            \hline
        \hlineB{3}
    \end{tabular}
\end{table}

\begin{lstlisting}[caption=sys\_yield的系统调用]
pub fn sys_yield() -> isize {
    suspend_current_and_run_next();
    0
}
\end{lstlisting}

依赖于task模块实现的suspend\_current\_and\_run\_next，其将会暂停当前执行的任务，并在内核中查找下一个运行状态为Ready的应用并得到其ID，若没有找到，则返回一个None。

\begin{lstlisting}[caption=sys\_fork的系统调用]
pub fn sys_fork() -> isize {
    let current_task = current_task().unwrap();
    let new_task = current_task.fork();
    let new_pid = new_task.pid.0;
    let trap_cx = new_task.inner_exclusive_access().get_trap_cx();
    trap_cx.x[10] = 0;  //x[10] is a0 reg
    add_task(new_task);
    new_pid as isize
}
\end{lstlisting}

new\_task的执行环境是从当前进程（父进程）中复制相关的环境, current\_ task.fork()这个动作会复制父进程的地址空间，同时会将父进程的弱引用计数存放到子进程的进程控制块中。\verb|trap_cx.x[10] = 0|子进程的 Trap 上下文中用来存放系统调用返回值的 a0 寄存器修改为 0 。而\verb|inner_exclusive_access|则将会返回一个可变引用的内部任务控制块。

\begin{lstlisting}[caption=sys\_pipe的系统调用]
pub fn sys_pipe(pipe: *mut usize) -> isize {
    let task = current_task().unwrap();
    let token = current_user_token();
    let mut inner = task.acquire_inner_lock();
    let (pipe_read, pipe_write) = make_pipe();
    let read_fd = inner.alloc_fd();
    inner.fd_table[read_fd] = Some(pipe_read);
    let write_fd = inner.alloc_fd();
    inner.fd_table[write_fd] = Some(pipe_write);
    *translated_refmut(token, pipe) = read_fd;
    *translated_refmut(token, unsafe { pipe.add(1) }) = write_fd;
    0
} 
\end{lstlisting}

\verb|make\_pipe|可以创建一个管道并获取管道的读写端，而inner.fd\_table[write\_fd] = Some(pipe\_write)则分别为管道的读端和写端分配文件描述符并将它们放置在文件描述符表中的相应位置，而在sys\_pipe的最后则是将读端和写端的文件描述符写回到应用地址空间。

\begin{lstlisting}[caption=sys\_sigactiion的系统调用]
pub fn sys_sigaction(
    signum: i32,
    action: *const SignalAction,
    old_action: *mut SignalAction,
) -> isize {
    // ... 任务创建  ...
    if signum as usize > MAX_SIG {
        return -1;
    }
    if let Some(flag) = SignalFlags::from_bits(1 << signum) {
        if check_sigaction_error(flag, action as usize, old_action as usize) {
            return -1;
        }
        let prev_action = inner.signal_actions.table[signum as usize];
        *translated_refmut(token, old_action) = prev_action;
        inner.signal_actions.table[signum as usize] = *translated_ref(token, action);
        0
    } else {
        -1
    }
}
\end{lstlisting}


check\_sigaction\_error 用来检查 sigaction 的参数是否有错误（有错误的话返回 true）。这里的检查比较简单，如果传入的 action 或者 old\_action 为空指针则视为错误。另一种错误则是信号类型为 SIGKILL 或者 SIGSTOP 。

sys\_sigaction 首先会调用 check\_sigactio\_error 进行检查，如果没有错误的话，则会使用 translated\_ref 将进程提交的信号处理例程保存到进程控制块，随后将此前的处理例程保存到进程中的指定位置。而保证translate\_ref能被正确调用的前提是类型 T 不会跨页，这将通过通过设置 SignalAction 对齐到 16 字节来保证这一点。

\subsection{文件系统}

\begin{table}[htb]
    \tableCapSet    % 使用此命令调整 caption 间距
    \caption{tiny 文件系统主要的系统调用}
    \label{table:c4tinyfssyscall}
    \centering
    \zihao{5}
    \begin{tabular}{c|c|c}
        \hlineB{3}  % 线宽为3倍的横线
        编号  & 系统调用               & 功能描述                \\
        \hlineB{2}  % 线宽为2倍的横线
            3 &sys\_open &打开/创建文件 \\
            \hline
            4 &sys\_close &关闭文件 \\
            \hline
        \hlineB{3}
    \end{tabular}
\end{table}

\begin{lstlisting}[caption=sys\_open的系统调用]
pub fn sys_open(path: *const u8, flags: u32) -> isize {
    // ... 获取 task, path, user 的相关信息 ...
    if let Some(inode) = open_file(
        path.as_str(),
        OpenFlags::from_bits(flags).unwrap()
    ) {
        let mut inner = task.acquire_inner_lock();
        let fd = inner.alloc_fd();
        inner.fd_table[fd] = Some(inode);
        fd as isize
    } else {
        -1
    }
}
\end{lstlisting}

其中，文件的的读写标记有OpenFlags::{RDONLY, WRONLY, RDWR, CREATE, TRUNC}，则可以通过open\_file基于EasyFileSystem对磁盘上进行文件的处理。open\_file将会接收两个参数，一个是文件名，关于文件名是一个比较泛化的概念，其文件名将会包含文件路径，在tiny的内核设计中，遵循了rCore的文件设计，处理文件的方式是通过ROOT\_INODE的根节点开始查找与之对应的文件，依次为基础对文件进行读写。


\subsection{并发处理}

\begin{table}[htb]
    \tableCapSet    % 使用此命令调整 caption 间距
    \caption{tiny 并发系统调用}
    \label{table:c4tinyconcurrencysyscall}
    \centering
    \zihao{5}
    \begin{tabular}{c|c|c}
        \hlineB{3}  % 线宽为3倍的横线
        编号  & 系统调用               & 功能描述                \\
        \hlineB{2}  % 线宽为2倍的横线
            1 &sys\_thread\_create &创建线程 \\
            \hline
        \hlineB{3}
    \end{tabular}
\end{table}

\begin{lstlisting}[caption=sys\_thread\_create的系统调用]
pub fn sys_thread_create(entry: usize, arg: usize) -> isize {
    // ... 创建相关的任务，并将新的任务加入到内核的调用机制中 ...
    let tasks = &mut process_inner.tasks;
    while tasks.len() < new_task_tid + 1 {
        tasks.push(None);
    }
    tasks[new_task_tid] = Some(Arc::clone(&new_task));
    let new_task_trap_cx = new_task_inner.get_trap_cx();
    *new_task_trap_cx = TrapContext::app_init_context(
        entry,
        new_task_res.ustack_top(),
        kernel_token(),
        new_task.kstack.get_top(),
        trap_handler as usize,
    );
    (*new_task_trap_cx).x[10] = arg;
    new_task_tid as isize
}
\end{lstlisting}

内核会为每个线程分配一组专属于该线程的资源：用户栈、Trap 上下文还有内核栈，前面两个在进程地址空间中，内核栈在内核地址空间中。这样这些线程才能相对独立地被调度和执行。相比于创建进程的 fork 系统调用，创建线程无需建立新的地址空间，

线程创建有两种方式：第一种是在创建进程的时候默认为这个进程创建一个主线程（创建进程又分为若干种方式）；第二种是通过 thread\_create 系统调用在当前进程内创建一个新的线程。参考第二中方式，则在线程创建的时候需要注意保存如下信息： 

\begin{itemize}
\item 线程的用户态栈：确保在用户态的线程能正常执行函数调用；
\item 线程的内核态栈：确保线程陷入内核后能正常执行函数调用；
\item 线程共享的跳板页和线程独占的 Trap 上下文：确保线程能正确的进行用户态与内核态间的切换；
\item 线程的任务上下文：线程在内核态的寄存器信息，用于线程切换。
\end{itemize}

其中new\_task\_trap\_cx，则初始化位于该线程在用户态地址空间中的 Trap 上下文：设置线程的函数入口点和用户栈，使得第一次进入用户态时能从指定位置开始正确执行；设置好内核栈和陷入函数指针 trap\_handler ，保证在 Trap 的时候用户态的线程能正确进入内核态。


\subsubsection{互斥锁}


在进程控制块中存有mutex\_list，其类型为Vec<Option<Arc<dyn Mutex > > >，数组构建一个含有多个可空槽位且槽位数可以拓展的互斥锁表，表中的每个元素都实现了 Mutex Trait ，是一种互斥锁实现。

\begin{lstlisting}[caption=互斥锁的实现]
impl Mutex for MutexBlocking {
    fn lock(&self) {
        let mut mutex_inner = self.inner.exclusive_access();
        if mutex_inner.locked {
            mutex_inner.wait_queue.push_back(current_task().unwrap());
            drop(mutex_inner);
            block_current_and_run_next();
        } else {
            mutex_inner.locked = true;
        }
    }

    fn unlock(&self) {
        let mut mutex_inner = self.inner.exclusive_access();
        assert!(mutex_inner.locked);
        if let Some(waking_task) = mutex_inner.wait_queue.pop_front() {
            wakeup_task(waking_task);
        } else {
            mutex_inner.locked = false;
        }
    }
}
\end{lstlisting}

对于 lock 来说，首先检查是否已经有线程在临界区中。如果 locked 为 true ，则将当前线程复制一份到阻塞队列中，然后调用 block\_current\_and\_run\_next 阻塞当前线程；否则当前线程可以进入临界区，将 locked 修改为 true 。

对于 unlock 来说，简单起见，假定当前线程一定持有锁（也就是所有的线程一定将 lock 和 unlock 配对使用），因此断言 locked 为 true 。接下来尝试从阻塞队列中取出一个线程，如果存在的话就将这个线程唤醒。被唤醒的线程将继续执行 lock 并返回，进而回到用户态进入临界区。在此期间 locked 始终为 true ，相当于 释放锁的线程将锁直接移交给这次唤醒的线程 。反之，如果阻塞队列中没有线程的话，则将 locked 改成 false ，让后来的线程能够进入临界区。


\subsubsection{条件变量}

在进程控制块中存有condvar\_list，其类型为Vec<Option<Arc<Condvar > > >，Condvar的内部基于一个阻塞队列。

\begin{lstlisting}[caption=条件变量的实现]
impl Condvar {
    // ... 初始化阻塞队列 wait_queue ...
    pub fn signal(&self) {
        let mut inner = self.inner.exclusive_access();
        if let Some(task) = inner.wait_queue.pop_front() {
            wakeup_task(task);
        }
    }
    pub fn wait_no_sched(&self) -> *mut TaskContext {
        self.inner.exclusive_session(|inner| {
            inner.wait_queue.push_back(current_task().unwrap());
        });
        block_current_task()
    }
    pub fn wait_with_mutex(&self, mutex: Arc<dyn Mutex>) {
        mutex.unlock();
        self.inner.exclusive_session(|inner| {
            inner.wait_queue.push_back(current_task().unwrap());
        });
        block_current_and_run_next();
        mutex.lock();
    }
}
\end{lstlisting}


signal 从阻塞队列中移除一个线程并调用唤醒原语 wakeup\_task 将其唤醒。wait 接收一个当前线程持有的锁作为参数。首先将锁释放，然后将当前线程挂在条件变量阻塞队列中，之后调用阻塞原语 block\_current\_and\_run\_next 阻塞当前线程。在被唤醒之后还需要重新获取锁，这样 wait 才能返回。

\subsubsection{信号量}

在进程控制块中存有semaphore\_list，其类型为Vec<Option<Arc<Semaphore > > >，Condvar的内部基于一个阻塞队列，还存在一个计数变量（即信号量基本思路中的整数变量 S）。信号量 Semaphore 支持三种操作：创建 new （带有一个参数 res\_count ，也即信号量初始可用资源数量 
 ）以及 up （也即 V 操作）和 down （也即 P 操作）。

\begin{lstlisting}[caption=信号量的实现]
impl Semaphore {
    pub fn new(res_count: usize) -> Self {
        Self {
            inner: unsafe {
                UPIntrFreeCell::new(SemaphoreInner {
                    count: res_count as isize,
                    wait_queue: VecDeque::new(),
                })
            },
        }
    }
    pub fn up(&self) {
        let mut inner = self.inner.exclusive_access();
        inner.count += 1;
        if inner.count <= 0 {
            if let Some(task) = inner.wait_queue.pop_front() {
                wakeup_task(task);
            }
        }
    }
    pub fn down(&self) {
        let mut inner = self.inner.exclusive_access();
        inner.count -= 1;
        if inner.count < 0 {
            inner.wait_queue.push_back(current_task().unwrap());
            drop(inner);
            block_current_and_run_next();
        }
    }
}
\end{lstlisting}

其实现逻辑：

信号量相比互斥锁是一种更为强大和灵活的同步原语。它用来描述这样一种同步需求：初始状态下，某种资源的可用数量为一个非负整数$\boldsymbol{\mathrm{N}}$。

整数变量count的含义如下：当count > 0时，表示还有count个可用资源；当count = 0时，表示所有可用资源恰好耗尽；当count < 0时，表示此时有count个线程被阻塞。显然count也应该被初始化为$\boldsymbol{\mathrm{N}}$。对于 down 操作，首先将 count减一，如果发现count < 0，说明之前 $\mathrm{count} \le 0$，一定没有可用资源了，于是需要阻塞当前线程；对于 up 操作，这里将count加一，可以这样理解：如果此时没有线程被阻塞则恢复 1 个可用资源；否则将阻塞线程数减少 1 ，因为当前线程将资源移交给了其中一个被阻塞的线程并唤醒了它。

\section{异步调度}

\subsection{用户空间和内核空间的异步执行逻辑}

\begin{lstlisting}[caption=用户空间的异步逻辑]
pub fn execute_async() {
    let shared_payload = unsafe { task::shared::SharedPayload::new(SHARED_PAYLOAD_BASE) };
    task::shared::run_until_ready(
        || unsafe { shared_payload.peek_task(task::shared::user_should_switch) },
        |task_repr| unsafe { shared_payload.delete_task(task_repr) },
        |task_repr, new_state| unsafe { shared_payload.set_task_state(task_repr, new_state) },
    );
}
\end{lstlisting}

得益于共享调度的设计，ring\_scheduler的物理地址无论在内核空间还是用户空间都是可见的，因此内核和用户可以通过run\_until\_ready来执行相应的异步任务， 即从ring\_scheduler中获取任务， 将任务(指针)存入调度器，改变调度器中原有任务的任务状态。


\subsection{异步事件的底层依赖: Event}

需要设计一个事件监听的工具，使得可以将同步的数据结构转化为异步的数据结果，为异步提供基础的依赖。

异步事件的内部同步的数据结构为:

\begin{lstlisting}[caption=异步事件底层的同步结构]
struct Inner {
    notified: AtomicUsize,
    list: Mutex<List>,
    cache: UnsafeCell<Entry>,
}
\end{lstlisting}

Inner中的notified用于通知已被通知的Entry的数目，如果所有条目都被通知了，或者没有条目被通知，该值都会被设置为usize::MAX。而list则是用于指向已被注册的监听的链表， 而Mutex提供在多线程中list资源的锁机制，以解决资源竞争带来的数据冲突。

\subsubsection{异步事件的一些原语}
\label{sssec:event}

\begin{lstlisting}[caption = 监听者的注册]
pub fn listen(&self) -> EventListener {
    let inner = self.inner();
    let listener = EventListener {
        inner: unsafe { Arc::clone(&ManuallyDrop::new(Arc::from_raw(inner))) },
        entry: Some(inner.lock().insert(inner.cache_ptr())),
    };

    // Make sure the listener is registered before whatever happens next.
    full_fence();
    listener
}
\end{lstlisting}

\begin{lstlisting}[caption = 通知一定数量的监听者]
pub fn notify(&self, n: usize) {
    full_fence();
    if let Some(inner) = self.try_inner() {
        if inner.notified.load(Ordering::Acquire) < n {
            inner.lock().notify(n);
        }
    }
}
\end{lstlisting}

\begin{lstlisting}[caption = 通知一定数量没有被通知的监听者]
pub fn notify_additional(&self, n: usize) {
    full_fence();

    if let Some(inner) = self.try_inner() {
        if inner.notified.load(Ordering::Acquire) < usize::MAX {
            inner.lock().notify_additional(n);
        }
    }
}
\end{lstlisting}

\begin{lstlisting}[caption=full\_fence]
fn full_fence() {
    core::sync::atomic::fence(Ordering::SeqCst);
}
\end{lstlisting}

full\_fence 该函数会阻止编译器和CPU围绕对某些类型的内春操作重新排序。使其可以在一些原子操作中创建同步关系。

\subsubsection{Event异步事件的状态}
\begin{lstlisting}[caption=Event的状态]
enum State {
    /// 刚刚被创建
    Created,
    /// 已经接收到一个通知
    ///
    /// 如果这是个 `additional` 通知，`bool` 将为 `true`
    Notified(bool),
    /// 正在被一个异步任务 `poll`，保存了任务的 `waker`
    Polling(Waker),
}
\end{lstlisting}

只用当状态为`State::Notified(bool)`的时候，事件才是被通知， 因此有如下的事件监听机制：

\begin{lstlisting}[caption=Event的事件获取并判断事件是否完成]
impl Future for EventListener {
    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        let mut list = self.inner.lock();

        let entry = match self.entry {
            None => unreachable!("cannot poll a completed `EventListener` future"),
            Some(entry) => entry,
        };
        // ...
    }
}
\end{lstlisting}


\begin{lstlisting}[caption=Event的事件Poll机制]
impl Future for EventListener {
    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        // ...
        let state = unsafe { &entry.as_ref().state };
        match state.replace(State::Notified(false)) {
            State::Notified(_) => {
                list.remove(entry, self.inner.cache_ptr());
                drop(list);
                self.entry = None;
                return Poll::Ready(());
            }
            State::Created => {
                state.set(State::Polling(cx.waker().clone()));
            }
            State::Polling(w) => {
                if w.will_wake(cx.waker()) {
                    state.set(State::Polling(w));
                } else {
                    state.set(State::Polling(cx.waker().clone()));
                }
            }
        }
        Poll::Pending
    }
}
\end{lstlisting}


当获取事件的状态的可变引用时， 当章台为Polling和Created的时候，事件将会被加入到注册的waker序列中，当为Notified时，事件将会从序列中移除，然后释放相应的资源，并返回Ready告知任务已经完成，其余状态统一返回Pending
